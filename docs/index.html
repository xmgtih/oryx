
<!DOCTYPE html>
<!--
 Generated by Apache Maven Doxia at 2015-04-21
 Rendered using Reflow Maven Skin 1.1.1 (http://andriusvelykis.github.io/reflow-maven-skin)
-->
<html  xml:lang="en" lang="en">

	<head>
		<meta charset="UTF-8" />
		<title>Oryx &#x2013; Documentation</title>
		<meta name="viewport" content="width=device-width, initial-scale=1.0" />
		<meta name="description" content="" />
		<meta http-equiv="content-language" content="en" />

		<link href="http://netdna.bootstrapcdn.com/bootswatch/2.3.2/united/bootstrap.min.css" rel="stylesheet" />
		<link href="http://netdna.bootstrapcdn.com/twitter-bootstrap/2.3.1/css/bootstrap-responsive.min.css" rel="stylesheet" />
		<link href="../css/bootswatch.css" rel="stylesheet" />
		<link href="../css/reflow-skin.css" rel="stylesheet" />


		<link href="../css/lightbox.css" rel="stylesheet" />

		<link href="../css/site.css" rel="stylesheet" />
		<link href="../css/print.css" rel="stylesheet" media="print" />

		<!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
		<!--[if lt IE 9]>
			<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
		<![endif]-->



	</head>

	<body class="page-docs-index project-oryx" data-spy="scroll" data-offset="60" data-target="#toc-scroll-target">

		<div class="navbar navbar-fixed-top">
			<div class="navbar-inner">
				<div class="container">
					<a class="btn btn-navbar" data-toggle="collapse" data-target="#top-nav-collapse">
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
					</a>
					<a class="brand" href="index.html">Oryx 2</a>
					<div class="nav-collapse collapse" id="top-nav-collapse">
						<ul class="nav pull-right">
							<li ><a href="../overview.html" title="Overview">Overview</a></li>
							<li class="active"><a href="" title="Documentation">Documentation</a></li>
							<li ><a href="../contribute.html" title="Contribute">Contribute</a></li>
							<li ><a href="../download.html" title="Download">Download</a></li>
						</ul>
					</div><!--/.nav-collapse -->
				</div>
			</div>
		</div>

	<div class="container">

	<!-- Masthead
	================================================== -->

	<header>
	<div class="jumbotron subhead">
		<div class="row" id="banner">
			<div class="span12">
				<div class="pull-left">
					<a href="http://oryxproject.github.io/oryx/" id="bannerLeft"><h1>Oryx</h1></a>
				</div>
				<div class="pull-right">
				</div>
			</div>
		</div>
	</div>
		<div>
			<ul class="breadcrumb">
				<li class="projectVersion version-date">Version: 2.0.0-alpha-1</li>
				<li class="divider">|</li>
				<li class="publishDate version-date">Last Published: 2015-04-21</li>
			</ul>
		</div>
	</header>

	<div class="main-body">
	<div class="row">
		<div class="span8">
			<div class="body-content">
<div class="page-header">
 <h1 id="documentation">Documentation</h1>
</div> 
<ul> 
 <li><a href="../project-reports.html">JavaDoc and Other Project Reports</a></li> 
 <li><a href="api-end-pt-ref.html">API Endpoint Reference</a></li> 
 <li><a href="faq-and-troubleshooting.html">FAQ and Trouble Shooting</a></li> 
 <li><a href="oryx-1-diff.html">Differences From Oryx 1</a></li> 
 <li><a href="oryx-2-first-release.html">Oryx 2 First Release</a></li> 
 <li><a class="externalLink" href="https://github.com/cloudera/oryx/wiki">Wiki</a></li> 
</ul> 
<h1 id="build_from_source">Build From Source</h1> 
<div class="section"> 
 <h2 id="Requirements">Requirements</h2> 
 <p>Building from source requires:</p> 
 <ul> 
  <li><a class="externalLink" href="http://git-scm.com/"><tt>git</tt></a>, or an IDE that supports Git</li> 
  <li><a class="externalLink" href="http://maven.apache.org/">Apache Maven</a> 3.0.0 or later</li> 
  <li><a class="externalLink" href="http://www.oracle.com/technetwork/java/javase/downloads/index.html">Java JDK</a> (not just JRE) 6 or later</li> 
 </ul> 
 <p>Some or all of these may already be installed on your development machine.</p> 
</div> 
<div class="section"> 
 <h2 id="Build">Build</h2> 
 <p>Clone the repository from GitHub in your desired local directory, which will create <tt>oryx</tt>. Build it:</p> 
 <div class="source"> 
  <div class="source"> 
   <pre>git clone https://github.com/cloudera/oryx.git
cd oryx
mvn -DskipTests install
</pre> 
  </div> 
 </div> 
 <p>This will build the following binaries:</p> 
 <ul> 
  <li>Serving Layer: <tt>serving/target/oryx-serving-x.y.z.jar</tt></li> 
  <li>Computation Layer: <tt>computation/target/oryx-computation-x.y.z.jar</tt></li> 
 </ul> 
 <h1 id="developing_from_source">Developing from Source</h1> 
 <p>Note that if you are interested in developing on Oryx, you should probably <a class="externalLink" href="https://help.github.com/articles/fork-a-repo">fork this repository</a> and then work on your own fork, so that you can submit pull requests with changes.</p> 
</div> 
<div class="section"> 
 <h2 id="Older_Hadoop_Version__230_Note">Older Hadoop Version (&lt; 2.3.0) Note</h2> 
 <p>To use Oryx with versions of Hadoop 2.x prior to 2.3.0, it is necessary to create compatible binaries by recompiling against the specific version of Hadoop you‚Äôre using. To do so, use the <tt>hadoop200</tt> profile and set the <tt>hadoop.version</tt> property.</p> 
 <p><tt>mvn -phadoop200 -Dhadoop.version=...</tt></p> 
 <h1 id="cluster_setup">Cluster Setup</h1> 
</div> 
<div class="section"> 
 <h2 id="Requirements">Requirements</h2> 
 <ul> 
  <li>Java 7 or later (JRE only is required) (<i>In the near future, Java 8 may be required</i>)</li> 
  <li>A Hadoop cluster running the following components: 
   <ul> 
    <li>Apache Hadoop 2.5.0 or later</li> 
    <li>Apache Zookeeper 3.4.5 or later</li> 
    <li>Apache Kafka 0.8.2 or later</li> 
    <li>Apache Spark 1.3.0 or later</li> 
   </ul></li> 
 </ul> 
 <p><a class="externalLink" href="http://www.cloudera.com/content/cloudera/en/products-and-services/cdh.html">CDH</a> 5.4.0 and later meet these requirements, although any Hadoop distribution with these components should work fine. While the rest of the instructions will refer to a CDH 5.4.0+ distribution, this is not a requirement.</p> 
 <p><i>Note that the ‚Äúalpha 1‚Äù release requires only Spark 1.2.0, and thus works with CDH 5.3.0+</i></p> 
 <p>A single-node cluster can be sufficient, although running all of these components on one machine may require a reasonable amount of RAM.</p> 
</div> 
<div class="section"> 
 <h2 id="Cluster_Setup">Cluster Setup</h2> 
 <p>Install and configure the Hadoop cluster normally. The following services need to be enabled:</p> 
 <ul> 
  <li>HDFS</li> 
  <li>YARN</li> 
  <li>Zookeeper</li> 
  <li>Kafka</li> 
  <li>Spark (on YARN)</li> 
 </ul> 
 <p>Note that for CDH, Kafka is available as a ‚ÄúCLABS 1.0.0‚Äù parcel from <a class="externalLink" href="http://www.cloudera.com/content/cloudera/en/developers/home/cloudera-labs/apache-kafka.html">Cloudera Labs</a>.</p> 
 <p>Determine the (possibly several) Kafka brokers that are configured in the cluster, under Instances, and note their hosts and port. The port is typically 9092. Same for the Zookeeper servers; the default port here is 2181. Default ports will be used in subsequent examples.</p> 
 <p>Where a Kafka broker or Zookeeper server is called for, you can and should specify a comma-separated list of <tt>host:port</tt> pairs where there are multiple hosts. Example: <tt>your-zk-1:2181,your-zk-2:2181</tt>.</p> 
 <p>Also note whether your Zookeeper instance is using a chroot path. This is simply a path suffixed to the <tt>host:port</tt>, like <tt>your-zk:2181/your-chroot</tt>. For example in CDH, Kafka uses a <tt>/kafka</tt> chroot, and subsequent examples will use this chroot. You can omit this if you are not using a chroot.</p> 
 <p>Note: if you have multiple Zookeeper servers, and a chroot, only add the chroot once, at the end: <tt>your-zk-1:2181,your-zk-2:2181/kafka</tt></p> 
</div> 
<div class="section"> 
 <h2 id="Verifying_Kafka_Optional">Verifying Kafka (Optional)</h2> 
 <p>To quickly verify that Kafka and ZK are running correctly:</p> 
 <div class="source"> 
  <div class="source"> 
   <pre>kafka-topics --create --zookeeper your-zk:2181/kafka \
  --replication-factor 1 --partitions 1 --topic test
kafka-console-consumer --zookeeper your-zk:2181/kafka \
  --topic test --from-beginning
</pre> 
  </div> 
 </div> 
 <p>In another console, take any text file (here <tt>data.csv</tt>) and send it to the topic:</p> 
 <div class="source"> 
  <div class="source"> 
   <pre>cat data.csv | kafka-console-producer \
  --broker-list your-kafka-broker:9092 --topic test
</pre> 
  </div> 
 </div> 
 <p>You should see the contents of the text file echoed onto the other consumer‚Äôs console soon thereafter.</p> 
 <p>Delete the test topic when done.</p> 
 <div class="source"> 
  <div class="source"> 
   <pre>kafka-topics --delete --zookeeper your-zk:2181/kafka --topic test
</pre> 
  </div> 
 </div> 
</div> 
<div class="section"> 
 <h2 id="Configuring_Kafka">Configuring Kafka</h2> 
 <p>Oryx will use two Kafka topics for data transport. One carries input data to the batch and Speed Layer, and the other carries model updates from there on to the Serving Layer. The default names of these topics are ‚ÄúOryxInput‚Äù and ‚ÄúOryxUpdate‚Äù respectively. They need to be created before Oryx is started.</p> 
 <p>Each can default to have one partition, but more can be configured if much higher read throughput is needed. The example below shows 1 partition. Replication factor can be any value, but 3 is recommended.</p> 
 <div class="source"> 
  <div class="source"> 
   <pre>kafka-topics --create --zookeeper your-zk:2181/kafka \
  --replication-factor 3 --partitions 1 --topic OryxInput
...
Created topic &quot;OryxInput&quot;.
</pre> 
  </div> 
 </div> 
 <div class="source"> 
  <div class="source"> 
   <pre>kafka-topics --create --zookeeper your-zk:2181/kafka \
  --replication-factor 3 --partitions 1 --topic OryxUpdate
...
Created topic &quot;OryxUpdate&quot;.
</pre> 
  </div> 
 </div> 
 <p>You may need to configure the retention time for one or both topics. In particular, it‚Äôs typically important to limit the retention time for the update topic, since the Speed and Serving Layer read the entire topic from the start on startup to catch up. Setting it to twice the Batch Layer update interval is a good start. For example, to set it to 2 days (2 * 24 * 60 * 60 * 1000 = 172800000 ms):</p> 
 <div class="source"> 
  <div class="source"> 
   <pre>kafka-topics --zookeeper your-zk:2181/kafka --alter --topic OryxUpdate \
  --config retention.ms=172800000
</pre> 
  </div> 
 </div> 
 <p>This is not as important for the input topic, which is not re-read from the beginning.</p> 
 <p>Continue to <a href="./Running-Oryx.html">Running-Oryx</a> to start the servers, and run an example.</p> 
 <h1 id="configuration">Configuration</h1> 
 <p>Refer to the default configuration file for a list and explanation of configuration parameters: <a href="/OryxProject/oryx/blob/master/framework/oryx-common/src/main/resources/reference.conf"><tt>reference.conf</tt></a></p> 
 <p>Skeleton examples may be found at:</p> 
 <ul> 
  <li><a href="/OryxProject/oryx/blob/master/app/conf/als-example.conf"><tt>app/conf/als-example.conf</tt></a></li> 
  <li><a href="/OryxProject/oryx/blob/master/app/conf/kmeans-example.conf"><tt>app/conf/kmeans-example.conf</tt></a></li> 
  <li><a href="/OryxProject/oryx/blob/master/app/conf/rdf-example.conf"><tt>app/conf/rdf-example.conf</tt></a></li> 
 </ul> 
 <h1 id="running_oryx">Running Oryx</h1> 
 <p><i>This is a temporary, manual process for distributing and running the binaries.</i></p> 
</div> 
<div class="section"> 
 <h2 id="Running">Running</h2> 
 <p>Download the <a class="externalLink" href="https://github.com/OryxProject/oryx/releases">latest release</a> of the Oryx Batch, Speed and Serving Layer, both <tt>.jar</tt> files and <tt>.sh</tt> scripts. Alternatively, build them from source (see <a href="./Building-from-Source.html">Building-from-Source</a>).</p> 
 <p>Copy binaries and scripts to machines that are part of the Hadoop cluster. They may be deployed on different machines, or on one for purposes of testing. The Speed and Batch Layers should run on at most one machine, each. The Serving Layer can run on many.</p> 
 <p>Create a configuration file for your application. You may start with the example in <a href="/OryxProject/oryx/blob/master/app/conf/als-example.conf">conf/als-example.conf</a>. Modify host names, ports and directories. In particular, choose data and model directories on HDFS that exist and will be accessible to the user running Oryx binaries.</p> 
 <p>Copy this config file as <tt>example.conf</tt> to the same directory as binaries and script on each machine.</p> 
 <p>Run the three Layers with:</p> 
 <div class="source"> 
  <div class="source"> 
   <pre>./run.sh --layer-jar oryx-batch-2.0.0-SNAPSHOT.jar --conf example.conf
...
./run.sh --layer-jar oryx-speed-2.0.0-SNAPSHOT.jar --conf example.conf
...
./run.sh --layer-jar oryx-serving-2.0.0-SNAPSHOT.jar --conf example.conf
</pre> 
  </div> 
 </div> 
 <p>These need not be on the same machine, but may be (if configuration specifies different ports for the Batch and Speed Layer Spark web UI, and the Serving Layer API port). The Serving Layer may be run on several machines.</p> 
 <p>That‚Äôs all!</p> 
</div> 
<div class="section"> 
 <h2 id="Trying_the_ALS_Example">Trying the ALS Example</h2> 
 <p>If you‚Äôve used the configuration above, you are running an instance of the ALS-based recommender application.</p> 
 <p>Obtain the [http://grouplens.org/datasets/movielens/](GroupLens 100k) data set and find the <tt>u.data</tt> file within. This needs to be converted to csv:</p> 
 <div class="source"> 
  <div class="source"> 
   <pre>tr '\t' ',' &lt; u.data &gt; data.csv
</pre> 
  </div> 
 </div> 
 <p>You may wish to monitor the content of the input and update topic while it is in action. <a href="./Cluster-Setup.html">Cluster-Setup</a> explains how to tail topics with <tt>kafka-console-consumer</tt>. The topics are named <tt>OryxInput</tt> and <tt>OryxUpdate</tt> by default.</p> 
 <p>Push the input to a Serving Layer, with a local command line tool like <tt>curl</tt>:</p> 
 <div class="source"> 
  <div class="source"> 
   <pre>wget --post-file data.csv \
  --output-document - \
  --header &quot;Content-Type: text/csv&quot; \
  http://your-serving-layer:8080/ingest
</pre> 
  </div> 
 </div> 
 <p>If you are tailing the input topic, you should see a large amount of CSV data flow to the topic:</p> 
 <div class="source"> 
  <div class="source"> 
   <pre>196,242,3.0,881250949186
196,242,3.0,881250949
186,302,3.0,891717742
22,377,1.0,878887116
244,51,2.0,880606923
166,346,1.0,886397596
298,474,4.0,884182806
...
</pre> 
  </div> 
 </div> 
 <p>Soon, you should also see the Batch Layer trigger a new computation. The example configuration starts one every 5 minutes.</p> 
 <p>The data is first written to HDFS. The example configuration has it written to directories under <tt>hdfs:///user/example/Oryx/data/</tt>. Within are directories named by timestamp, each containing Hadoop <tt>part-r-*</tt> files, which contain the input as <tt>SequenceFile</tt>s of <tt>Text</tt>. Although not pure text, printing them should yield some recognizable data because it is in fact text.</p> 
 <div class="source"> 
  <div class="source"> 
   <pre>SEQorg.apache.hadoop.io.Textorg.apache.hadoop.io.TextÔøΩÔøΩÔøΩÔøΩ^ÔøΩ]ÔøΩXÿ≥NÔøΩ22,377,1.0,87888711662...
</pre> 
  </div> 
 </div> 
 <p>A model computation then begins. This should show as a number of new distributed jobs the Batch Layer. Its Spark UI is started at <tt>http://your-batch-layer:4040</tt> in the example configuration.</p> 
 <p>Soon the model will complete, and it will be persisted as a combination of PMML and supporting data files in a subdirectory of <tt>hdfs:///user/example/Oryx/model/</tt>. For example, the <tt>model.pmml.gz</tt> files are compressed PMML files containing elements like:</p> 
 <div class="source"> 
  <div class="source"> 
   <pre>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;yes&quot;?&gt;
&lt;PMML xmlns=&quot;http://www.dmg.org/PMML-4_2&quot; version=&quot;4.2.1&quot;&gt;
    &lt;Header&gt;
        &lt;Application name=&quot;Oryx&quot;/&gt;
        &lt;Timestamp&gt;2014-12-18T04:48:54-0800&lt;/Timestamp&gt;
    &lt;/Header&gt;
    &lt;Extension name=&quot;X&quot; value=&quot;X/&quot;/&gt;
    &lt;Extension name=&quot;Y&quot; value=&quot;Y/&quot;/&gt;
    &lt;Extension name=&quot;features&quot; value=&quot;10&quot;/&gt;
    &lt;Extension name=&quot;lambda&quot; value=&quot;0.001&quot;/&gt;
    &lt;Extension name=&quot;implicit&quot; value=&quot;true&quot;/&gt;
    &lt;Extension name=&quot;alpha&quot; value=&quot;1.0&quot;/&gt;
    &lt;Extension name=&quot;XIDs&quot;&gt;56 168 222 343 397 ...
     ...
</pre> 
  </div> 
 </div> 
 <p>The <tt>X/</tt> and <tt>Y/</tt> subdirectories next to it contain feature vectors, like:</p> 
 <div class="source"> 
  <div class="source"> 
   <pre>[56,[0.5746282834154238,-0.08896614131333057,-0.029456222765775263,
  0.6039821219690552,0.1497901814774658,-0.018654312114339863,
  -0.37342063488340266,-0.2370768843521807,1.148260034028485,
  1.0645643656769153]]
[168,[0.8722769882777296,0.4370416943031704,0.27402044461549885,
  -0.031252701117490456,-0.7241385753098256,0.026079081002582338,
  0.42050973702065714,0.27766923396205817,0.6241033215856671,
  -0.48530795198811266]]
...
</pre> 
  </div> 
 </div> 
 <p>If you are tailing the update topic, you should also see these values published to the topic.</p> 
 <p>The Serving Layer will pick this up soon thereafter, and the <tt>/ready</tt> endpoint will return status <tt>200 OK</tt>:</p> 
 <div class="source"> 
  <div class="source"> 
   <pre>wget --quiet --output-document - \
  --server-response \
  http://your-serving-layer:8080/ready
...
  HTTP/1.1 200 OK
  Content-Length: 0
  Date: Thu, 18 Dec 2014 13:26:53 GMT
  Server: Oryx
</pre> 
  </div> 
 </div> 
 <div class="source"> 
  <div class="source"> 
   <pre>wget --quiet --output-document - \
  http://your-serving-layer:8080/recommend/17
...
50,0.7749542842056966
275,0.7373013861581563
258,0.731818692628511
181,0.7049967175706345
127,0.704518989947498
121,0.7014631029793741
15,0.6954683387287907
288,0.6774889711024022
25,0.6663619887033064
285,0.6398968471343595
</pre> 
  </div> 
 </div> 
 <p>Congratulations, it‚Äôs a live recommender!</p> 
 <p>When done, all processes can be killed with Ctrl-C safely.</p> 
 <p>See more about endpoints that are available in <a href="./API-Endpoint-Reference.html">API-Endpoint-Reference</a>.</p> 
 <h1 id="making_an_oryx_app">Making an Oryx App</h1> 
 <p>Oryx comes with an ‚Äúapp tier‚Äù, implementations of actual Batch, Speed and Serving Layer logic for recommendation, clustering and classification. However, any implementation may be used with Oryx. They can be mixed and matched too. For example, you could reimplement the Batch Layer for ALS-related recommendation and instead supply this alternative implementation while still using the provided ALS Serving and Speed Layers.</p> 
</div> 
<div class="section"> 
 <h2 id="Creating_an_App">Creating an App</h2> 
 <p>In each case, creating a custom Batch, Speed or Serving Layer app amounts to implementing one Java interface or Scala trait. These interfaces/traits are found in the <tt>oryx-api</tt> module within the project.</p> 
 <table border="0" class="bodyTable table table-striped table-hover"> 
  <thead> 
   <tr class="a"> 
    <th align="right"> </th> 
    <th align="left">Java </th> 
   </tr> 
  </thead> 
  <tbody> 
   <tr class="b"> 
    <td align="right">Batch </td> 
    <td align="left"><tt>com.cloudera.oryx.api.batch.BatchLayerUpdate</tt> </td> 
   </tr> 
   <tr class="a"> 
    <td align="right">Speed </td> 
    <td align="left"><tt>com.cloudera.oryx.api.speed.SpeedModelManager</tt> </td> 
   </tr> 
   <tr class="b"> 
    <td align="right">Serving </td> 
    <td align="left"><tt>com.cloudera.oryx.api.serving.ServingModelManager</tt> </td> 
   </tr> 
  </tbody> 
 </table> 
 <table border="0" class="bodyTable table table-striped table-hover"> 
  <thead> 
   <tr class="a"> 
    <th align="right"> </th> 
    <th align="left">Scala </th> 
   </tr> 
  </thead> 
  <tbody> 
   <tr class="b"> 
    <td align="right">Batch </td> 
    <td align="left"><tt>com.cloudera.oryx.api.batch.ScalaBatchLayerUpdate</tt> </td> 
   </tr> 
   <tr class="a"> 
    <td align="right">Speed </td> 
    <td align="left"><tt>com.cloudera.oryx.api.speed.ScalaSpeedModelManager</tt> </td> 
   </tr> 
   <tr class="b"> 
    <td align="right">Serving </td> 
    <td align="left"><tt>com.cloudera.oryx.api.serving.ScalaServingModelManager</tt> </td> 
   </tr> 
  </tbody> 
 </table> 
</div> 
<div class="section"> 
 <h2 id="Building_an_App">Building an App</h2> 
 <p>To access these interfaces/traits in your application, add a dependency on <tt>com.cloudera.oryx:oryx-api</tt>. The scope should be <tt>provided</tt>.</p> 
 <p>In Maven, this would mean adding a dependency like:</p> 
 <div class="source"> 
  <div class="source"> 
   <pre>&lt;dependencies&gt;
  &lt;dependency&gt;
    &lt;groupId&gt;com.cloudera.oryx&lt;/groupId&gt;
    &lt;artifactId&gt;oryx-api&lt;/artifactId&gt;
    &lt;scope&gt;provided&lt;/scope&gt;
    &lt;version&gt;2.0.0&lt;/version&gt;
  &lt;/dependency&gt;
&lt;/dependencies&gt;
</pre> 
  </div> 
 </div> 
 <p>A minimal skeleton project can be found at <a href="/OryxProject/oryx/tree/master/app/example">example/</a>.</p> 
 <p>Compile your code and create a JAR file containing only your implementation, and any supporting third-party code. With Maven, this happens with <tt>mvn package</tt>.</p> 
</div> 
<div class="section"> 
 <h2 id="Customizing_an_Oryx_App">Customizing an Oryx App</h2> 
 <p>When deploying the prepackaged applications that come with Oryx, in some cases, it‚Äôs possible to supply additional implementations to customize their behavior. For example, the ALS recommender application exposes a <tt>com.cloudera.oryx.app.als.RescorerProvider</tt> interface. These app-specific API classes are found in module <tt>oryx-app-api</tt>. Implementations of interfaces like these can be compiled, packaged and deployed in the same way described here for stand-alone applications.</p> 
 <div class="source"> 
  <div class="source"> 
   <pre>&lt;dependencies&gt;
  &lt;dependency&gt;
    &lt;groupId&gt;com.cloudera.oryx&lt;/groupId&gt;
    &lt;artifactId&gt;oryx-app-api&lt;/artifactId&gt;
    &lt;scope&gt;provided&lt;/scope&gt;
    &lt;version&gt;2.0.0&lt;/version&gt;
  &lt;/dependency&gt;
&lt;/dependencies&gt;
</pre> 
  </div> 
 </div> 
</div> 
<div class="section"> 
 <h2 id="Deploying_an_App">Deploying an App</h2> 
 <p>Copy the resulting JAR file ‚Äì call it <tt>myapp.jar</tt> ‚Äì to the directory containing the Oryx binary JAR file it will be run with.</p> 
 <p>Change your Oryx <tt>.conf</tt> file to refer to your custom Batch, Speed or Serving implementation class, as appropriate.</p> 
 <p>When running the Batch / Speed / Serving Layers, add <tt>--app-jar myapp.jar</tt> to the <tt>run.sh</tt> command line.</p> 
 <h1 id="handling_failure">Handling Failure</h1> 
 <p>Eventually, you‚Äôll want to stop one or more of the Layers running, or restart it. Or maybe a server decides to die. What happens then? What‚Äôs the worst that can happen?</p> 
</div> 
<div class="section"> 
 <h2 id="Data_Loss">Data Loss</h2> 
 <p>Historical data is saved in HDFS, which should be configured for replication. HDFS ensures data is stored reliably. Kafka is also designed to cope with failure when configured to use replication.</p> 
 <p>That is, there is nothing special to do here in order to ensure that data is never completely lost. It is the job of HDFS and Kafka to always be available and not lose data.</p> 
</div> 
<div class="section"> 
 <h2 id="Server_Failure">Server Failure</h2> 
 <p>In general, all three Layer server processes should run continuously, and can and should be restarted immediately if they have to be stopped, or in case of a failure. This can be accomplished with an init script or similar mechanism (not included, yet).</p> 
 <div class="section"> 
  <h3 id="Serving_Layer">Serving Layer</h3> 
  <p>The Serving Layer has no state. On startup, it reads all models and updates available on the update topic. It begins answering queries as soon as any first, valid model is available. For this reason, it‚Äôs desirable to limit the retention time for the update topic.</p> 
  <p>The operation of the Serving Layer is not distributed. Each instance is independent, and may stop or start without affecting others.</p> 
 </div> 
 <div class="section"> 
  <h3 id="Speed_Layer">Speed Layer</h3> 
  <p>The Speed Layer also has no state, and also reads all models and updates available on the update topic. It begins producing updates as soon as it has a valid model. It also begins reading from the input topic, and at the moment, always reads from the latest offset.</p> 
  <p>The Speed Layer uses Spark Streaming and Spark for some of its computation. Spark has the responsibility of dealing with failures during computation in the cluster and retrying tasks.</p> 
  <p>Spark Streaming‚Äôs Kafka integration can in some cases recover from failure of the receiver that is reading from Kafka. If the entire process dies and is restarted, and <tt>oryx.id</tt> has been set, then reading will be able to resume from the last offset recorded by Kafka. (Otherwise, it will resume reading from the latest offset. This means data that arrived while no Speed Layer was running will not have produced any update.) Also, data that arrives before the Speed Layer has a model is ignored too. It effectively adopts ‚Äúat most once‚Äù semantics.</p> 
  <p>Because the role of the Speed Layer is to provide an approximate, ‚Äúbest effort‚Äù update to the last published model, this behavior is generally no problem, and desirable because of its simplicity.</p> 
 </div> 
 <div class="section"> 
  <h3 id="Batch_Layer">Batch Layer</h3> 
  <p>The Batch Layer is the most complex, since it does generate some state:</p> 
  <ul> 
   <li>Historical data, is always persisted to HDFS</li> 
   <li>If the app chooses to, additional state like models can be persisted to HDFS as well as topics</li> 
  </ul> 
  <p>It also is most sensitive to reading data multiple times or not at all, since it is the component that creates the ‚Äúofficial‚Äù next model.</p> 
  <p>As with the Speed Layer, Spark and Spark Streaming handles many of the failure scenarios during computation. It also manages storing data to HDFS and is responsible for avoiding writing the same data twice.</p> 
  <p>Applications are responsible for recovering their own ‚Äòstate‚Äô; currently, applications built on the Oryx ML tier write state into unique subdirectories, and will simply produce a new set of state in a new directory when restarted. Previous state, if it exists, will have been completely written or not at all.</p> 
  <p>The Batch Layer also currently adopts the same ‚Äúat most once‚Äù semantics as the Speed Layer. As above, if the entire process dies and is restarted, and <tt>oryx.id</tt> has been set, then reading will be able to resume from the last offset recorded by Kafka, and otherwise, it will resume reading from the latest offset.</p> 
 </div> 
</div>
			</div>
		</div>
		<div class="span4">
			<div id="toc-sidebar">
				<div class="well">
					<ul class="nav nav-list">
						<li class="nav-header">Table of Contents</li>
		<li><a href="#documentation" title="Documentation">Documentation</a>
		<li class="dropdown"><a href="#build_from_source" title="Build From Source">Build From Source <b class="caret"></b></a>
			<ul class="nav nav-list">
		<li><a href="#Requirements" title="Requirements">Requirements</a>
		<li><a href="#Build" title="Build">Build</a>
				<li class="divider"></li>
			</ul>
		</li>
		<li class="dropdown"><a href="#developing_from_source" title="Developing from Source">Developing from Source <b class="caret"></b></a>
			<ul class="nav nav-list">
		<li><a href="#Older_Hadoop_Version__230_Note" title="Older Hadoop Version (< 2.3.0) Note">Older Hadoop Version (< 2.3.0) Note</a>
				<li class="divider"></li>
			</ul>
		</li>
		<li class="dropdown"><a href="#cluster_setup" title="Cluster Setup">Cluster Setup <b class="caret"></b></a>
			<ul class="nav nav-list">
		<li><a href="#Requirements" title="Requirements">Requirements</a>
		<li><a href="#Cluster_Setup" title="Cluster Setup">Cluster Setup</a>
		<li><a href="#Verifying_Kafka_Optional" title="Verifying Kafka (Optional)">Verifying Kafka (Optional)</a>
		<li><a href="#Configuring_Kafka" title="Configuring Kafka">Configuring Kafka</a>
				<li class="divider"></li>
			</ul>
		</li>
		<li><a href="#configuration" title="Configuration">Configuration</a>
		<li class="dropdown"><a href="#running_oryx" title="Running Oryx">Running Oryx <b class="caret"></b></a>
			<ul class="nav nav-list">
		<li><a href="#Running" title="Running">Running</a>
		<li><a href="#Trying_the_ALS_Example" title="Trying the ALS Example">Trying the ALS Example</a>
				<li class="divider"></li>
			</ul>
		</li>
		<li class="dropdown"><a href="#making_an_oryx_app" title="Making an Oryx App">Making an Oryx App <b class="caret"></b></a>
			<ul class="nav nav-list">
		<li><a href="#Creating_an_App" title="Creating an App">Creating an App</a>
		<li><a href="#Building_an_App" title="Building an App">Building an App</a>
		<li><a href="#Customizing_an_Oryx_App" title="Customizing an Oryx App">Customizing an Oryx App</a>
		<li><a href="#Deploying_an_App" title="Deploying an App">Deploying an App</a>
				<li class="divider"></li>
			</ul>
		</li>
		<li class="dropdown"><a href="#handling_failure" title="Handling Failure">Handling Failure <b class="caret"></b></a>
			<ul class="nav nav-list">
		<li><a href="#Data_Loss" title="Data Loss">Data Loss</a>
		<li class="dropdown"><a href="#Server_Failure" title="Server Failure">Server Failure <b class="caret"></b></a>
			<ul class="nav nav-list">
		<li><a href="#Serving_Layer" title="Serving Layer">Serving Layer</a>
		<li><a href="#Speed_Layer" title="Speed Layer">Speed Layer</a>
		<li><a href="#Batch_Layer" title="Batch Layer">Batch Layer</a>
				<li class="divider"></li>
			</ul>
		</li>
			</ul>
		</li>
					</ul>
				</div>
			</div>
		</div>
	</div>
	</div>

	</div><!-- /container -->

	<!-- Footer
	================================================== -->
	<footer class="well">
		<div class="container">
			<div class="row">
				<div class="span9 bottom-nav">
					<ul class="nav nav-list">
					</ul>
				</div>
			</div>
		</div>
	</footer>

	<div class="container subfooter">
		<div class="row">
			<div class="span12">
				<p class="pull-right"><a href="#">Back to top</a></p>
				<p class="copyright">Copyright &copy;2014-2015. All Rights Reserved.</p>
				<p><a href="http://github.com/andriusvelykis/reflow-maven-skin" title="Reflow Maven skin">Reflow Maven skin</a> by <a href="http://andrius.velykis.lt" target="_blank" title="Andrius Velykis">Andrius Velykis</a>.</p>
			</div>
		</div>
	</div>

	<!-- Le javascript
	================================================== -->
	<!-- Placed at the end of the document so the pages load faster -->
	<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>

	<script src="http://netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
	<script src="../js/lightbox.min.js"></script>
	<script src="../js/reflow-scroll.js"></script>

	<script src="../js/reflow-skin.js"></script>

	</body>
</html>
